{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version is  1.13.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "\n",
    "from train_utils import plot_confusion_matrix, make_dataframe\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "print(\"Tensorflow version is \", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size:  403\n",
      "Training set size:  283\n",
      "Validation set size:  53\n",
      "Test set size:  67\n",
      "Total size:  501\n",
      "Training set size:  351\n",
      "Validation set size:  66\n",
      "Test set size:  84\n",
      "Total size:  410\n",
      "Training set size:  288\n",
      "Validation set size:  54\n",
      "Test set size:  68\n",
      "Total size:  594\n",
      "Training set size:  417\n",
      "Validation set size:  78\n",
      "Test set size:  99\n",
      "Total size:  527\n",
      "Training set size:  370\n",
      "Validation set size:  69\n",
      "Test set size:  88\n"
     ]
    }
   ],
   "source": [
    "width_image = 224\n",
    "height_image = 224\n",
    "batch_size = 32\n",
    "img_shape = (width_image, height_image, 3)\n",
    "\n",
    "categories = os.listdir('dataset\\\\v2')\n",
    "data_frames = make_dataframe('dataset\\\\v2', validation_percentage = 0.13, test_percentage=0.17)\n",
    "\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=15.\n",
    ")\n",
    "validation_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1709 validated image filenames belonging to 5 classes.\n",
      "Found 320 validated image filenames belonging to 5 classes.\n",
      "Found 406 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# make generator\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=data_frames[0],\n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    class_mode = 'categorical',\n",
    "    target_size = (width_image, height_image),\n",
    "    batch_size = batch_size)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    dataframe=data_frames[1],\n",
    "    x_col = 'path',\n",
    "    y_col = 'label',\n",
    "    class_mode = 'categorical',\n",
    "    target_size=(width_image, height_image),\n",
    "    batch_size = batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=data_frames[2],\n",
    "    x_col = 'path',\n",
    "    y_col = 'label',\n",
    "    class_mode = 'categorical',\n",
    "    target_size=(width_image, height_image),\n",
    "    batch_size = batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Petreti Andrea\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# get pre-trained MobileNet V2\n",
    "#base_model = tf.keras.applications.MobileNetV2(input_shape=img_shape,\n",
    "#                                                include_top=False,\n",
    "#                                                weights='imagenet')\n",
    "\n",
    "#base_model = tf.keras.applications.InceptionResNetV2(input_shape=img_shape,\n",
    "#                                                include_top=False,\n",
    "#                                                weights='imagenet')\n",
    "\n",
    "base_model = tf.keras.applications.densenet.DenseNet121(input_shape=img_shape,\n",
    "                                                include_top=False,\n",
    "                                                weights='imagenet')\n",
    "\n",
    "# feature extraction reuse, True for fine-tuning see tensorflow\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create model over pre-trained net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model over pre-trained graph\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "#    keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.001),\n",
    "#                       activation=tf.nn.relu, input_shape=(len(categories),)),\n",
    "#    keras.layers.Dropout(0.5),\n",
    "#    keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.001),\n",
    "#                       activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(len(categories), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the optmizer, loss function and metric for evaluate the training\n",
    "optimizer = keras.optimizers.Adam()\n",
    "# optimizer = keras.optimizers.Nadam()\n",
    "# optimizer = keras.optimizers.Adadelta()\n",
    "# tensorflow guide use:\n",
    "#optimizer = tf.keras.optimizers.RMSprop(lr=0.0001)\n",
    "\n",
    "model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tranining Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 5s 527ms/step - loss: 0.9502 - acc: 0.6375\n",
      "54/54 [==============================] - 29s 544ms/step - loss: 1.3420 - acc: 0.4734 - val_loss: 0.9502 - val_acc: 0.6375\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.7605 - acc: 0.7219\n",
      "54/54 [==============================] - 26s 474ms/step - loss: 0.8162 - acc: 0.7068 - val_loss: 0.7605 - val_acc: 0.7219\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.6427 - acc: 0.7688\n",
      "54/54 [==============================] - 30s 552ms/step - loss: 0.6618 - acc: 0.7601 - val_loss: 0.6427 - val_acc: 0.7688\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.5783 - acc: 0.7937\n",
      "54/54 [==============================] - 31s 568ms/step - loss: 0.5707 - acc: 0.8163 - val_loss: 0.5783 - val_acc: 0.7937\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 3s 297ms/step - loss: 0.5372 - acc: 0.8313\n",
      "54/54 [==============================] - 31s 572ms/step - loss: 0.5128 - acc: 0.8327 - val_loss: 0.5372 - val_acc: 0.8313\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.5067 - acc: 0.8250\n",
      "54/54 [==============================] - 31s 567ms/step - loss: 0.4977 - acc: 0.8250 - val_loss: 0.5067 - val_acc: 0.8250\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 3s 297ms/step - loss: 0.5054 - acc: 0.8250\n",
      "54/54 [==============================] - 32s 598ms/step - loss: 0.4457 - acc: 0.8461 - val_loss: 0.5054 - val_acc: 0.8250\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 3s 296ms/step - loss: 0.4830 - acc: 0.8250\n",
      "54/54 [==============================] - 31s 568ms/step - loss: 0.4225 - acc: 0.8555 - val_loss: 0.4830 - val_acc: 0.8250\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 3s 300ms/step - loss: 0.4798 - acc: 0.8250\n",
      "54/54 [==============================] - 31s 576ms/step - loss: 0.4222 - acc: 0.8525 - val_loss: 0.4798 - val_acc: 0.8250\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.4509 - acc: 0.8438\n",
      "54/54 [==============================] - 32s 590ms/step - loss: 0.4082 - acc: 0.8602 - val_loss: 0.4509 - val_acc: 0.8438\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "steps_per_epoch = train_generator.n // batch_size\n",
    "validation_steps = validation_generator.n // batch_size\n",
    "test_steps = test_generator.n // batch_size\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs = epochs, \n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = validation_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1709\n",
      "Number of layers in the base model:  427\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.n)\n",
    "#Enable chage of all net weight's including the pre-trained\n",
    "epochs_fine = 200\n",
    "model.trainable = True\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the level to fine-tune\n",
    "fine_tune_at = 200\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable =  False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet121 (Model)          (None, 7, 7, 1024)        7037504   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 7,042,629\n",
      "Trainable params: 5,125\n",
      "Non-trainable params: 7,037,504\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# recompile model with optimizer\n",
    "optimizer = keras.optimizers.SGD(lr=0.0001, momentum=0.9, nesterov=True)\n",
    "#optimizer = tf.keras.optimizers.RMSprop(lr=2e-5)\n",
    "\n",
    "model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 [==============================] - 6s 587ms/step - loss: 0.4434 - acc: 0.8594\n",
      "54/54 [==============================] - 32s 599ms/step - loss: 0.3520 - acc: 0.8800 - val_loss: 0.4434 - val_acc: 0.8594\n",
      "Epoch 2/200\n",
      "10/10 [==============================] - 3s 283ms/step - loss: 0.4427 - acc: 0.8594\n",
      "54/54 [==============================] - 26s 490ms/step - loss: 0.3813 - acc: 0.8672 - val_loss: 0.4427 - val_acc: 0.8594\n",
      "Epoch 3/200\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.4408 - acc: 0.8625\n",
      "54/54 [==============================] - 32s 588ms/step - loss: 0.3692 - acc: 0.8812 - val_loss: 0.4408 - val_acc: 0.8625\n",
      "Epoch 4/200\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.4401 - acc: 0.8625\n",
      "54/54 [==============================] - 32s 590ms/step - loss: 0.3737 - acc: 0.8701 - val_loss: 0.4401 - val_acc: 0.8625\n",
      "Epoch 5/200\n",
      "10/10 [==============================] - 3s 299ms/step - loss: 0.4397 - acc: 0.8594\n",
      "54/54 [==============================] - 32s 589ms/step - loss: 0.3890 - acc: 0.8689 - val_loss: 0.4397 - val_acc: 0.8594\n",
      "Epoch 6/200\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.4388 - acc: 0.8625\n",
      "54/54 [==============================] - 31s 581ms/step - loss: 0.3701 - acc: 0.8789 - val_loss: 0.4388 - val_acc: 0.8625\n",
      "Epoch 7/200\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4393 - acc: 0.8625\n",
      "54/54 [==============================] - 32s 589ms/step - loss: 0.3628 - acc: 0.8765 - val_loss: 0.4393 - val_acc: 0.8625\n",
      "Epoch 8/200\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.4398 - acc: 0.8625\n",
      "54/54 [==============================] - 29s 546ms/step - loss: 0.3696 - acc: 0.8724 - val_loss: 0.4398 - val_acc: 0.8625\n",
      "Epoch 9/200\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.4385 - acc: 0.8594\n",
      "54/54 [==============================] - 29s 545ms/step - loss: 0.3752 - acc: 0.8736 - val_loss: 0.4385 - val_acc: 0.8594\n",
      "Epoch 10/200\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.4382 - acc: 0.8594\n",
      "54/54 [==============================] - 31s 567ms/step - loss: 0.3654 - acc: 0.8812 - val_loss: 0.4382 - val_acc: 0.8594\n",
      "Epoch 11/200\n",
      "10/10 [==============================] - 3s 293ms/step - loss: 0.4383 - acc: 0.8594\n",
      "54/54 [==============================] - 30s 554ms/step - loss: 0.3564 - acc: 0.8841 - val_loss: 0.4383 - val_acc: 0.8594\n",
      "Epoch 12/200\n",
      "10/10 [==============================] - 3s 301ms/step - loss: 0.4373 - acc: 0.8594\n",
      "54/54 [==============================] - 29s 541ms/step - loss: 0.3730 - acc: 0.8800 - val_loss: 0.4373 - val_acc: 0.8594\n",
      "Epoch 13/200\n",
      "10/10 [==============================] - 3s 301ms/step - loss: 0.4364 - acc: 0.8594\n",
      "54/54 [==============================] - 30s 555ms/step - loss: 0.3708 - acc: 0.8724 - val_loss: 0.4364 - val_acc: 0.8594\n",
      "Epoch 14/200\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.4354 - acc: 0.8594\n",
      "54/54 [==============================] - 30s 564ms/step - loss: 0.3683 - acc: 0.8789 - val_loss: 0.4354 - val_acc: 0.8594\n",
      "Epoch 15/200\n",
      "10/10 [==============================] - 3s 293ms/step - loss: 0.4348 - acc: 0.8594\n",
      "54/54 [==============================] - 30s 553ms/step - loss: 0.3774 - acc: 0.8637 - val_loss: 0.4348 - val_acc: 0.8594\n",
      "Epoch 16/200\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.4350 - acc: 0.8594\n",
      "54/54 [==============================] - 30s 557ms/step - loss: 0.3710 - acc: 0.8748 - val_loss: 0.4350 - val_acc: 0.8594\n",
      "Epoch 17/200\n",
      "10/10 [==============================] - 3s 297ms/step - loss: 0.4361 - acc: 0.8562\n",
      "54/54 [==============================] - 30s 548ms/step - loss: 0.3642 - acc: 0.8795 - val_loss: 0.4361 - val_acc: 0.8562\n",
      "Epoch 18/200\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4336 - acc: 0.8625\n",
      "54/54 [==============================] - 30s 563ms/step - loss: 0.3640 - acc: 0.8719 - val_loss: 0.4336 - val_acc: 0.8625\n",
      "Epoch 19/200\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.4345 - acc: 0.8625\n",
      "54/54 [==============================] - 30s 553ms/step - loss: 0.3724 - acc: 0.8760 - val_loss: 0.4345 - val_acc: 0.8625\n",
      "Epoch 20/200\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.4327 - acc: 0.8562\n",
      "54/54 [==============================] - 30s 547ms/step - loss: 0.3710 - acc: 0.8760 - val_loss: 0.4327 - val_acc: 0.8562\n",
      "Epoch 21/200\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.4319 - acc: 0.8562\n",
      "54/54 [==============================] - 29s 546ms/step - loss: 0.3592 - acc: 0.8730 - val_loss: 0.4319 - val_acc: 0.8562\n",
      "Epoch 22/200\n",
      " 7/54 [==>...........................] - ETA: 20s - loss: 0.3874 - acc: 0.8661"
     ]
    }
   ],
   "source": [
    "# fit fine-tuning\n",
    "history_fine = model.fit_generator(train_generator,\n",
    "                                   steps_per_epoch = steps_per_epoch,\n",
    "                                   epochs = epochs_fine,\n",
    "                                   validation_data=validation_generator,\n",
    "                                   validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Validation accuracy/loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# training and validation accuracy/loss\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "if('history_fine' in globals()):\n",
    "    acc += history_fine.history['acc']\n",
    "    val_acc += history_fine.history['val_acc']\n",
    "    loss += history_fine.history['loss']\n",
    "    val_loss += history_fine.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,max(plt.ylim())])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "Y_pred = model.predict_generator(test_generator, test_steps)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_generator.classes, y_pred))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report')\n",
    "print(classification_report(test_generator.classes, y_pred, target_names=categories))\n",
    "\n",
    "# evaluate keras model with model.evaluate()\n",
    "x, y = zip(*(test_generator[i] for i in range(len(test_generator))))\n",
    "x_test, y_test = np.vstack(x), np.vstack(y)\n",
    "loss, acc = model.evaluate(x_test, y_test, batch_size=32)\n",
    "\n",
    "print(\"Accuracy: {0:0.1f}%\".format(acc * 100))\n",
    "print(\"Loss: {0:0.1f}%\".format(loss * 100))\n",
    "\n",
    "\n",
    "plot_confusion_matrix(test_generator.classes, y_pred, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "name = 'adam_densnet121.h5'\n",
    "model.save(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_extractor = tf.keras.applications.densenet.DenseNet121(\n",
    "    input_shape=img_shape,\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    pooling='avg'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model over pre-trained graph, its same to pass pooling='avg'\n",
    "#model_extractor = tf.keras.Sequential([\n",
    "#   base_model_extractor\n",
    "#    keras.layers.GlobalAveragePooling2D()\n",
    "#])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "import sklearn\n",
    "from sklearn.model_selection import cross_validate, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.externals import joblib\n",
    " \n",
    "def train_svm_classifer(features, labels, model_output_path):\n",
    "    \"\"\"\n",
    "    train_svm_classifer will train a SVM, saved the trained and SVM model and\n",
    "    report the classification performance\n",
    " \n",
    "    features: array of input features\n",
    "    labels: array of labels associated with the input features\n",
    "    model_output_path: path for storing the trained svm model\n",
    "    \"\"\"\n",
    "    # save 20% of data for performance evaluation\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)\n",
    " \n",
    "    param = [\n",
    "        {\n",
    "            \"kernel\": [\"linear\"],\n",
    "            \"C\": [1, 10, 100, 1000]\n",
    "        },\n",
    "        {\n",
    "            \"kernel\": [\"rbf\"],\n",
    "            \"C\": [1, 10, 100, 1000],\n",
    "            \"gamma\": [1e-2, 1e-3, 1e-4, 1e-5]\n",
    "        }\n",
    "    ]\n",
    " \n",
    "    # request probability estimation\n",
    "    svm = SVC(probability=True)\n",
    " \n",
    "    # 10-fold cross validation, use 4 thread as each fold and each parameter set can be train in parallel\n",
    "    clf = GridSearchCV(svm, param,\n",
    "            cv=10, n_jobs=8, verbose=3)\n",
    " \n",
    "    clf.fit(X_train, y_train)\n",
    " \n",
    "    if os.path.exists(model_output_path):\n",
    "        joblib.dump(clf.best_estimator_, model_output_path)\n",
    "    else:\n",
    "        print(\"Cannot save trained svm model to {0}.\".format(model_output_path))\n",
    " \n",
    "    print(\"\\nBest parameters set:\")\n",
    "    print(clf.best_params_)\n",
    " \n",
    "    y_predict=clf.predict(X_test)\n",
    " \n",
    "    labels=sorted(list(set(labels)))\n",
    "    print(\"\\nConfusion matrix:\")\n",
    "    print(\"Labels: {0}\\n\".format(\",\".join(labels)))\n",
    "    print(confusion_matrix(y_test, y_predict, labels=labels))\n",
    "\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_test, y_predict))\n",
    "    \n",
    "def extract_features(generator, model, size):\n",
    "    features = np.empty((size, 1024))\n",
    "    labels = []\n",
    "    for i in range(0, size):\n",
    "        img, label = generator.next()\n",
    "        feature = model.predict(img)\n",
    "        features[i,:] = np.squeeze(feature)\n",
    "        labels.append(categories[np.argmax(label)])\n",
    "        print(\"{0:.0f}%\".format((i/size) * 100), end=\"\\r\")\n",
    "    return features, np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create from all dataset, the svm split into training and test sets\n",
    "train_svm_generator = train_datagen.flow_from_directory(\n",
    "    directory='dataset\\\\v2'\n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    class_mode = 'categorical',\n",
    "    target_size = (width_image, height_image),\n",
    "    batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = extract_features(train_svm_generator, base_model_extractor, size=len(train_svm_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_svm_classifer(features, labels, 'aa.bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
